{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae80666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88eb67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import olympus\n",
    "from olympus.datasets import Dataset\n",
    "from olympus.evaluators import Evaluator\n",
    "from olympus.emulators import Emulator\n",
    "from olympus.campaigns import Campaign\n",
    "from olympus.planners import Planner\n",
    "from olympus.scalarizers import Scalarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3493f2",
   "metadata": {},
   "source": [
    "## CASE STUDY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b67b0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs1_datasets = ['redoxmers']#'dye_lasers']\n",
    "cs1_planners = [\n",
    "    #'RandomSearch', \n",
    "    #'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd7d4aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Botorch ON redoxmers ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[WARNING] Current dataset has descriptors, but user has overidden their use\n",
      "\u001b[0m\u001b[1;33m[WARNING] Current dataset has descriptors, but user has overidden their use\n",
      "\u001b[0m/opt/anaconda3/envs/olympus/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in cs1_datasets:\n",
    "    for planner_name in cs1_planners:\n",
    "        \n",
    "        print(f'\\nTESTING {planner_name} ON {dataset_name} ...\\n')\n",
    "            \n",
    "        if dataset_name == 'dye_lasers':\n",
    "            # fully categorical, lookup table\n",
    "            dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(dataset.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(dataset.param_space)\n",
    "            campaign.set_value_space(dataset.value_space)\n",
    "            \n",
    "            scalarizer = Scalarizer(\n",
    "                kind='Chimera', \n",
    "                value_space=dataset.value_space,\n",
    "                goals=['max', 'min', 'max'],\n",
    "                tolerances=[0.5, 0.5, 0.5],\n",
    "                absolutes=[False, False, False]\n",
    "            )\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=dataset,\n",
    "                campaign=campaign,\n",
    "                scalarizer=scalarizer,\n",
    "            )\n",
    "        \n",
    "        elif dataset_name == 'redoxmers':\n",
    "            # fully categorical, lookup table\n",
    "            dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "            if planner_name == 'Botorch':\n",
    "                from olympus.planners.planner_botorch import Botorch\n",
    "                planner = Botorch(goal='minimize', use_descriptors=False)\n",
    "            else:\n",
    "                planner = Planner(kind=planner_name)\n",
    "        \n",
    "            planner.set_param_space(dataset.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(dataset.param_space)\n",
    "            campaign.set_value_space(dataset.value_space)\n",
    "            \n",
    "            scalarizer = Scalarizer(\n",
    "                kind='Chimera', \n",
    "                value_space=dataset.value_space,\n",
    "                goals=['min', 'min', 'min'],\n",
    "                tolerances=[0.5, 0.5, 0.5],\n",
    "                absolutes=[False, False, False]\n",
    "            )\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=dataset,\n",
    "                campaign=campaign,\n",
    "                scalarizer=scalarizer,\n",
    "            )\n",
    "            \n",
    "        evaluator.optimize(num_iter=15)\n",
    "        \n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fffb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign.observations.get_params()\n",
    "campaign.observations.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c27c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign.scalarized_observations.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759f8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538ac47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fca5412",
   "metadata": {},
   "source": [
    "## CASE STUDY 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf02d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# SUZUKI MIYAURA\n",
    "#----------------\n",
    "\n",
    "#suzuki_datasets = ['suzuki', 'suzuki_i', 'suzuki_ii', 'suzuki_iii', 'suzuki_iv', 'suzuki_edbo']\n",
    "suzuki_datasets = ['suzuki_i', 'suzuki_ii', 'suzuki_iii', 'suzuki_iv'] #['suzuki_edbo']\n",
    "\n",
    "suzuki_planners = [\n",
    "    #'RandomSearch', \n",
    "    'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    #'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "]  \n",
    "#suzuki_planners = ['RandomSearch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182aaff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Genetic ON suzuki_i ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_i...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:102: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  trainable=trainable)\n",
      "/home/riley/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:112: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  trainable=trainable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "TESTING Genetic ON suzuki_ii ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_ii...\n",
      "\u001b[0mDone!\n",
      "\n",
      "TESTING Genetic ON suzuki_iii ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_iii...\n",
      "\u001b[0mDone!\n",
      "\n",
      "TESTING Genetic ON suzuki_iv ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_iv...\n",
      "\u001b[0mDone!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in suzuki_datasets:\n",
    "    for planner_name in suzuki_planners:\n",
    "        \n",
    "        print(f'\\nTESTING {planner_name} ON {dataset_name} ...\\n')\n",
    "        \n",
    "        if dataset_name == 'suzuki': \n",
    "            \n",
    "            # fully continuous, emulated dataset\n",
    "            emulator = Emulator(dataset=dataset_name, model='BayesNeuralNet')\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(emulator.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(emulator.param_space)\n",
    "            campaign.set_value_space(emulator.value_space)\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=emulator,\n",
    "                campaign=campaign,\n",
    "            )\n",
    "            \n",
    "        elif dataset_name == 'suzuki_edbo':\n",
    "            \n",
    "            # fully categorical, lookup table\n",
    "            dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(dataset.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(dataset.param_space)\n",
    "            campaign.set_value_space(dataset.value_space)\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=dataset,\n",
    "                campaign=campaign,\n",
    "            )\n",
    "            \n",
    "        elif dataset_name in ['suzuki_i', 'suzuki_ii', 'suzuki_iii', 'suzuki_iv']:\n",
    "            \n",
    "            # mixed parameter, emulator, multi-objective optimization\n",
    "            emulator = Emulator(dataset=dataset_name, model='BayesNeuralNet')\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(emulator.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(emulator.param_space)\n",
    "            campaign.set_value_space(emulator.value_space)\n",
    "            \n",
    "            scalarizer = Scalarizer(\n",
    "                kind='Chimera', \n",
    "                value_space=emulator.value_space,\n",
    "                goals=['max', 'max'],\n",
    "                tolerances=[0.9, 0.0],\n",
    "                absolutes=[False, False]\n",
    "            )\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=emulator,\n",
    "                campaign=campaign,\n",
    "                scalarizer=scalarizer,\n",
    "            )\n",
    "        \n",
    "        evaluator.optimize(num_iter=10)\n",
    "        \n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign.observations.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaff1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25cfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "# BUCHWALD-HARTWIG\n",
    "#------------------\n",
    "\n",
    "buchwald_datasets = ['buchwald_a','buchwald_b','buchwald_c','buchwald_d','buchwald_e']\n",
    "\n",
    "buchwald_planners = [\n",
    "    #'RandomSearch', \n",
    "    'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    #'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e8c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Genetic ON buchwald_a ...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Individual' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46469/1856721414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/evaluators/evaluator.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, num_iter)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# get new params from planner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplanner_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_constriants\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"simplex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/abstract_planner.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, observations, return_as)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalarizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/abstract_planner.py\u001b[0m in \u001b[0;36mask\u001b[0;34m(self, return_as)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_generated\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# check that the parameters suggested are within the bounds of our param_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/planner_genetic/wrapper_deap.py\u001b[0m in \u001b[0;36m_ask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m                                 \u001b[0;31m# keep doing this if by chance we did not do any cross-over or mutation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsprings_to_be_evaluated\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_offsprings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# evaluate one offspring at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/planner_genetic/wrapper_deap.py\u001b[0m in \u001b[0;36m_generate_offsprings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                         \u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Performing cross-over operation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"INFO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mchild1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mchild2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/deap/tools/selection.py\u001b[0m in \u001b[0;36mselTournament\u001b[0;34m(individuals, k, tournsize, fit_attr)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[1;32m     65\u001b[0m     \u001b[0mchosen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0maspirants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mchosen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspirants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Individual' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "buchwald_campaigns = []\n",
    "\n",
    "for dataset_name in buchwald_datasets:\n",
    "    for planner_name in buchwald_planners:\n",
    "        \n",
    "        print(f'\\nTESTING {planner_name} ON {dataset_name} ...\\n')\n",
    "        \n",
    "        dataset = Dataset(kind=dataset_name)\n",
    "        planner = Planner(kind=planner_name)\n",
    "        planner.set_param_space(dataset.param_space)\n",
    "        \n",
    "        campaign = Campaign()\n",
    "        campaign.set_param_space(dataset.param_space)\n",
    "        campaign.set_value_space(dataset.value_space)\n",
    "        \n",
    "        evaluator = Evaluator(\n",
    "            planner=planner, \n",
    "            emulator=dataset,\n",
    "            campaign=campaign,\n",
    "        )\n",
    "        \n",
    "        evaluator.optimize(num_iter=15)\n",
    "        \n",
    "        print('Done!')\n",
    "        \n",
    "        buchwald_campaigns.append(campaign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b330d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fa6946a",
   "metadata": {},
   "source": [
    "## CASE STUDY 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "403fbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs3_datasets = ['dye_lasers'] #'redoxmers']\n",
    "cs3_planners = [\n",
    "    #'RandomSearch', \n",
    "    #'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "] \n",
    "cs3_scalarizers = ['Chimera', 'WeightedSum', 'Parego'] # 'ConstrainedAsf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55aa7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Botorch ON dye_lasers WITH Chimera ...\n",
      "\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n",
      "\n",
      "TESTING Botorch ON dye_lasers WITH WeightedSum ...\n",
      "\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n",
      "\n",
      "TESTING Botorch ON dye_lasers WITH Parego ...\n",
      "\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in cs3_datasets:\n",
    "    for planner_name in cs3_planners:\n",
    "        for scalarizer_name in cs3_scalarizers:\n",
    "        \n",
    "            print(f'\\nTESTING {planner_name} ON {dataset_name} WITH {scalarizer_name} ...\\n')\n",
    "\n",
    "            if dataset_name == 'dye_lasers':\n",
    "                # fully categorical, lookup table\n",
    "                dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "                planner = Planner(kind=planner_name)\n",
    "                planner.set_param_space(dataset.param_space)\n",
    "\n",
    "                campaign = Campaign()\n",
    "                campaign.set_param_space(dataset.param_space)\n",
    "                campaign.set_value_space(dataset.value_space)\n",
    "\n",
    "                if scalarizer_name == 'Chimera':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Chimera', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['max', 'min', 'max'],\n",
    "                        tolerances=[0.5, 0.5, 0.5],\n",
    "                        absolutes=[False, False, False]\n",
    "                    )\n",
    "                elif scalarizer_name == 'Parego':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Parego', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['max', 'min', 'max'],\n",
    "                        rho=0.05,\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'WeightedSum':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='WeightedSum', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['max', 'min', 'max'],\n",
    "                        weights=[0.33, 0.33, 0.33],\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'ConstrainedAsf':\n",
    "                    pass\n",
    "                    # TODO: implement this! \n",
    "                    \n",
    "\n",
    "                evaluator = Evaluator(\n",
    "                    planner=planner, \n",
    "                    emulator=dataset,\n",
    "                    campaign=campaign,\n",
    "                    scalarizer=scalarizer,\n",
    "                )\n",
    "\n",
    "            elif dataset_name == 'redoxmers':\n",
    "                # fully categorical, lookup table\n",
    "                dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "                planner = Planner(kind=planner_name)\n",
    "                planner.set_param_space(dataset.param_space)\n",
    "\n",
    "                campaign = Campaign()\n",
    "                campaign.set_param_space(dataset.param_space)\n",
    "                campaign.set_value_space(dataset.value_space)\n",
    "\n",
    "                if scalarizer_name == 'Chimera':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Chimera', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['min', 'min', 'min'],\n",
    "                        tolerances=[0.5, 0.5, 0.5],\n",
    "                        absolutes=[False, False, False]\n",
    "                    )\n",
    "                elif scalarizer_name == 'Parego':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Parego', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['min', 'min', 'min'],\n",
    "                        rho=0.05,\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'WeightedSum':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='WeightedSum', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['min', 'min', 'min'],\n",
    "                        weights=[0.33, 0.33, 0.33],\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'ConstrainedAsf':\n",
    "                    pass\n",
    "                    # TODO: implement this! \n",
    "\n",
    "                evaluator = Evaluator(\n",
    "                    planner=planner, \n",
    "                    emulator=dataset,\n",
    "                    campaign=campaign,\n",
    "                    scalarizer=scalarizer,\n",
    "                )\n",
    "\n",
    "            evaluator.optimize(num_iter=15)\n",
    "\n",
    "            print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba506ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90878652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7f11ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CN(C)/C(N(C)C)=N\\\\C(C)(C)C' == 'CN(C)/C(N(C)C)=N\\\\C(C)(C)C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043b1679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C)(C)C)C(C)(C)C''CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C)(C)C)C(C)(C)C' == 'CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C)(C)C)C(C)(C)C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011a462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)C(C)(C)C)C(OC)=CC=C2OC'=='CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)C(C)(C)C)C(OC)=CC=C2OC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "befd8741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CN(C)/C(N(C)C)=N\\\\C(C)(C)C'=='CN(C)/C(N(C)C)=N\\\\C(C)(C)C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfdab9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'o1ccc(n1)c2ccccc2'=='o1ccc(n1)c2ccccc2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336710d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Ic1cccnc1'=='Ic1cccnc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fef3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(kind='buchwald_e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf741e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aryl_halide</th>\n",
       "      <th>additive</th>\n",
       "      <th>base</th>\n",
       "      <th>ligand</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>o1ccc(n1)c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...</td>\n",
       "      <td>44.330847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>o1ccc(n1)c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C...</td>\n",
       "      <td>88.16754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>o1ccc(n1)c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...</td>\n",
       "      <td>84.556615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>o1ccc(n1)c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)...</td>\n",
       "      <td>69.795902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aryl_halide           additive                       base  \\\n",
       "568   Ic1cccnc1  o1ccc(n1)c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "577   Ic1cccnc1  o1ccc(n1)c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "594   Ic1cccnc1  o1ccc(n1)c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "791   Ic1cccnc1  o1ccc(n1)c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "\n",
       "                                                ligand      yield  \n",
       "568  CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...  44.330847  \n",
       "577  CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C...   88.16754  \n",
       "594  CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...  84.556615  \n",
       "791  CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)...  69.795902  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.data\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "df[(df['aryl_halide']=='Ic1cccnc1')&(df['additive']=='o1ccc(n1)c2ccccc2')&(df['base']=='CN(C)/C(N(C)C)=N\\\\C(C)(C)C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00163faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aryl_halide</th>\n",
       "      <th>additive</th>\n",
       "      <th>base</th>\n",
       "      <th>ligand</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>o1ccc(n1)c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)...</td>\n",
       "      <td>69.795902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aryl_halide           additive                       base  \\\n",
       "791   Ic1cccnc1  o1ccc(n1)c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "\n",
       "                                                ligand      yield  \n",
       "791  CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)...  69.795902  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\n",
    "    (df['aryl_halide']=='Ic1cccnc1')&\n",
    "    (df['additive']=='o1ccc(n1)c2ccccc2')&\n",
    "    (df['base']=='CN(C)/C(N(C)C)=N\\C(C)(C)C')&\n",
    "    (df['ligand']=='CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)C(C)(C)C)C(OC)=CC=C2OC')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3d7c1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aryl_halide</th>\n",
       "      <th>additive</th>\n",
       "      <th>base</th>\n",
       "      <th>ligand</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clc1cccnc1</td>\n",
       "      <td>o1nccc1c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...</td>\n",
       "      <td>4.169293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clc1cccnc1</td>\n",
       "      <td>CCOC(=O)c1onc(C)c1</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...</td>\n",
       "      <td>2.014672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clc1cccnc1</td>\n",
       "      <td>CCOC(=O)c1cc(C)on1</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...</td>\n",
       "      <td>16.173827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Clc1cccnc1</td>\n",
       "      <td>o1nccc1c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C...</td>\n",
       "      <td>15.194521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Clc1cccnc1</td>\n",
       "      <td>CCOC(=O)c1onc(C)c1</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C...</td>\n",
       "      <td>3.149733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>Fc1cccc(F)c1c2oncc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...</td>\n",
       "      <td>56.573875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>C(N(Cc1ccccc1)c2oncc2)c3ccccc3</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...</td>\n",
       "      <td>59.162165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>Cc1onc(c1)n2cccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...</td>\n",
       "      <td>62.559565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>COC(=O)c1cc(on1)c2sccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...</td>\n",
       "      <td>55.264663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Ic1cccnc1</td>\n",
       "      <td>o1ccc(n1)c2ccccc2</td>\n",
       "      <td>CN(C)/C(N(C)C)=N\\C(C)(C)C</td>\n",
       "      <td>CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)...</td>\n",
       "      <td>69.795902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aryl_halide                        additive                       base  \\\n",
       "1    Clc1cccnc1                 o1nccc1c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "4    Clc1cccnc1              CCOC(=O)c1onc(C)c1  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "7    Clc1cccnc1              CCOC(=O)c1cc(C)on1  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "10   Clc1cccnc1                 o1nccc1c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "13   Clc1cccnc1              CCOC(=O)c1onc(C)c1  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "..          ...                             ...                        ...   \n",
       "780   Ic1cccnc1             Fc1cccc(F)c1c2oncc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "783   Ic1cccnc1  C(N(Cc1ccccc1)c2oncc2)c3ccccc3  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "786   Ic1cccnc1               Cc1onc(c1)n2cccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "789   Ic1cccnc1         COC(=O)c1cc(on1)c2sccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "791   Ic1cccnc1               o1ccc(n1)c2ccccc2  CN(C)/C(N(C)C)=N\\C(C)(C)C   \n",
       "\n",
       "                                                ligand      yield  \n",
       "1    CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...   4.169293  \n",
       "4    CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...   2.014672  \n",
       "7    CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C3CCCCC3)...  16.173827  \n",
       "10   CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C...  15.194521  \n",
       "13   CC(C)C(C=C(C(C)C)C=C1C(C)C)=C1C2=CC=CC=C2P(C(C...   3.149733  \n",
       "..                                                 ...        ...  \n",
       "780  CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...  56.573875  \n",
       "783  CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...  59.162165  \n",
       "786  CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...  62.559565  \n",
       "789  CC(C1=C(C2=C(OC)C=CC(OC)=C2P(C34CC5CC(C4)CC(C5...  55.264663  \n",
       "791  CC(C)C1=CC(C(C)C)=CC(C(C)C)=C1C2=C(P(C(C)(C)C)...  69.795902  \n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['base']=='CN(C)/C(N(C)C)=N\\\\C(C)(C)C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d837e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympus",
   "language": "python",
   "name": "olympus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
